import Base.+, Base.-

mutable struct RewardFunction
    values::Array{<:Number}
    Ï€::Policy
    Ï€áµ¦::Array{<:AbstractFloat,2}
    invT::Array{<:AbstractFloat,2}
    ð“›::Float64
    âˆ‡ð“›::Array{<:AbstractFloat,1}
    RewardFunction(values::Array{<:Number}) = new(values)
end

function +(r::RewardFunction, values::Array{<:AbstractFloat})
    RewardFunction(r.values+values)
end

function -(r::RewardFunction, values::Array{<:AbstractFloat})
    RewardFunction(r.values-values)
end

"""
    Sample a new reward value for every state from gaussian
"""
function sample(::Type{RewardFunction}, features)
    RewardFunction(rand(Normal(0,1), features))
end

"""
    Calculates proposal value of new reward
"""
function proposal_distribution(râ‚::RewardFunction, râ‚‚::RewardFunction, âˆ‡logTarget::Array, Ï„)
    D = size(râ‚.values,1)
    g = râ‚.values - râ‚‚.values - 0.5*Ï„^2 * âˆ‡logTarget
    g = inv(-2*Ï„^2) * norm(g)^2
    # This is the correct calculation, but the initial constant cancels out
    # g = inv( (2*Ï€*Ï„^2)^(D/2) ) * exp(g)
    # @show g
    # exp(g)
    g
end
