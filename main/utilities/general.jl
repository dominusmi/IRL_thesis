import Base: +,-,/,*,convert

+(x::LoggedFloat, y::Number) = x.value+y
-(x::LoggedFloat, y::Number) = x.value-y
*(x::LoggedFloat, y::Number) = x.value*y
/(x::LoggedFloat, y::Number) = x.value/y
+(y::Number, x::LoggedFloat) = x+y
-(y::Number, x::LoggedFloat) = y-x.value
*(y::Number, x::LoggedFloat) = x*y
/(y::Number, x::LoggedFloat) = y/x.value
+(x::LoggedFloat, y::LoggedFloat) = LoggedFloat(x.value+y.value)
-(x::LoggedFloat, y::LoggedFloat) = LoggedFloat(x.value-y.value)
*(x::LoggedFloat, y::LoggedFloat) = LoggedFloat(x.value*y.value)
/(x::LoggedFloat, y::LoggedFloat) = LoggedFloat(x.value/y.value)
-(x::LoggedFloat) = -x.value
convert(::Type{Float64}, x::LoggedFloat) = x.value

"""
    Calculates inv(I-Î³Pâ‚šáµ¢), where Pâ‚šáµ¢ is the matrix of transition probabilities
    of size SxS
"""
function calInvTransition(mdp, Ï€áµ¦, Î³)
    n_states = size(Ï€áµ¦,1)
    I = eye(n_states)
    Pâ‚šáµ¢ = Ï€2transition(mdp, Ï€áµ¦)
    inv( I-Î³*Pâ‚šáµ¢ )
end

"""
    Calculates the derivative of Q with respect to a specific feature
"""
function caldQâ‚–!(dQâ‚–, mdp, invT, Ï€áµ¦, k, glb)
    states = ordered_states(mdp)
    Ï€â‚ = zeros(size(states,1)-1)

    # Ï€ "marginal"
    for s in states[1:end-1]
        si      = state_index(mdp, s)
        Ï€â‚[si]  = sum( Ï€áµ¦[si,:] ) * glb.Ï•[si,k]
    end

    # dQ for each action
    for a in actions(mdp)
        ai = action_index(mdp,a)
        dQâ‚–[:,ai] = glb.Ï•[:,k] + mdp.discount_factor * glb.Pâ‚[ai] * invT * Ï€â‚
    end
end


"""
    Calculates the LOG likelihood of a cluster
"""
function calð“›(mdp, Ï€áµ¦, Ï‡, glb)
    ð“›  = 0.
    for (m,trajectory) in enumerate(Ï‡)
        traj_size = size(trajectory.state_hist,1)-1
        ð“› += trajectory_likelihood(mdp, trajectory, Ï€áµ¦, glb)
        # for (h,state) in enumerate(trajectory.state_hist[1:end-1])
        #     sâ‚• = state_index(mdp, state)
        #     aâ‚• = action_index(mdp, trajectory.action_hist[h])
        #     ð“› += log(Ï€áµ¦[sâ‚•,aâ‚•])
        # end
    end
    ð“›
end

"""
   Returns the likelihood and the gradient of the likelihood given a Boltzmann
   policy and a set of trajectories
"""
function calâˆ‡ð“›(mdp, invT, Ï€áµ¦, Ï‡, glb::Globals)
    # ð“›  = 0.
    âˆ‡ð“› = zeros(glb.n_features)
    for k in 1:glb.n_features
        dQâ‚– = zeros( glb.n_states, glb.n_actions )
        caldQâ‚–!(dQâ‚–, mdp, invT, Ï€áµ¦, k, glb)

        # Calculates total gradient over trajectories
        for (m,trajectory) in enumerate(Ï‡)
            traj_size = size(trajectory.state_hist,1)-1
            for (h,state) in enumerate(trajectory.state_hist[1:end-1])
                sâ‚• = state_index(mdp, state)
                aâ‚• = action_index(mdp, trajectory.action_hist[h])

                # ð“› += state_action_lh(Ï€áµ¦,sâ‚•,aâ‚•)
                # ð“› += state_action_lh(Ï€áµ¦,sâ‚•,aâ‚•) / traj_size

                dl_dÎ¸â‚– = glb.Î² * ( dQâ‚–[sâ‚•,aâ‚•] - sum( [ state_action_lh(Ï€áµ¦,sâ‚•,aiâ») * dQâ‚–[sâ‚•,aiâ»] for aiâ» in glb.actions_i ] ) )
                âˆ‡ð“›[k] += dl_dÎ¸â‚–
            end
        end
    end
    âˆ‡ð“›
end



function load_reward_log(path_to_file)
    load(path_to_file)
end

"""
    Tunes Ï„ in order to get an acceptance rate between 0.4 and 0.8
"""
function update_Ï„(Ï„, t, changed_log)
    change = 0.
    t>=20 ? println("Last update: $(Ï„.last_modified), current rate: $(sum(changed_log[t-19:t])/20)") : nothing
    if t >= 20 && t-Ï„.last_modified >= 5
        acc_rate = sum(changed_log[t-19:t])/20
        if acc_rate < 0.3
            change = -Ï„/10
        # elseif acc_rate < 0.5
            # Ï„ *= 0.9
        elseif acc_rate > 0.8
            # change = (1-Ï„)/10
            change = Ï„/10
        # elseif acc_rate > 0.7
            # Ï„ *= 1.1
        end
        if abs(change) > 1e-4
            Ï„ = LoggedFloat(Ï„+change, t)
            println("Acceptance rate was $acc_rate, changed Ï„ to $(Ï„.value)")
        end
    end
    Ï„
end
